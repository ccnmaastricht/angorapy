{"debug": false, "env_name": "CartPole-v1", "state_dim": 4, "n_actions": 2, "continuous_control": false, "horizon": 100, "workers": 8, "discount": 0.99, "learning_rate": 0.001, "clip": 0.2, "c_entropy": 0.009999999776482582, "c_value": 0.5, "lam": 0.95, "gradient_clipping": null, "clip_values": true, "tbptt_length": 1, "lr_schedule_type": null, "builder_function_name": "build_ffn_True_models", "is_recurrent": false, "iteration": 0, "current_fps": 0, "gathering_fps": 0, "optimization_fps": 0, "device": "CPU:0", "model_export_dir": "storage/saved_models/exports/", "agent_id": 1578307644, "agent_directory": "storage/saved_models/states//1578307644/", "total_frames_seen": 0, "total_episodes_seen": 0, "episode_reward_history": [], "episode_length_history": [], "cycle_reward_history": [], "cycle_length_history": [], "entropy_history": [], "policy_loss_history": [], "value_loss_history": [], "time_dicts": [], "underflow_history": [], "preprocessor": {"StateNormalizationWrapper": [10, [-0.08530279230326407, -2.4086233833170703e+37, -0.0012339286506176002, 1.7116203197640556e+37], [9.773129027740499, 2.5031781818173822e+76, 0.10630997612394508, 2.6470880574117228e+76], 4], "RewardNormalizationWrapper": [0, 0, 1]}, "distribution": "CategoricalPolicyDistribution"}